<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#09090b">
    <title>Identity Verification</title>
    <style>
        :root {
            --bg: #09090b;
            --surface: #18181b;
            --surface-2: #27272a;
            --border: #3f3f46;
            --text: #fafafa;
            --text-muted: #a1a1aa;
            --success: #22c55e;
            --warning: #f59e0b;
            --error: #ef4444;
            --primary: #3b82f6;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; -webkit-tap-highlight-color: transparent; }

        html {
            height: 100%;
            height: -webkit-fill-available;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
            background: var(--bg);
            color: var(--text);
            min-height: 100vh;
            min-height: -webkit-fill-available;
            display: flex;
            justify-content: center;
            align-items: flex-start;
            padding-top: env(safe-area-inset-top);
            padding-bottom: env(safe-area-inset-bottom);
            overflow-x: hidden;
        }

        .app {
            width: 100%;
            max-width: 440px;
            padding: 12px;
            padding-bottom: calc(12px + env(safe-area-inset-bottom));
        }

        /* Mobile-specific adjustments */
        @media (max-width: 480px) {
            .app {
                padding: 8px;
                padding-bottom: calc(8px + env(safe-area-inset-bottom));
            }
            
            .header h1 { font-size: 18px; }
            .header p { font-size: 12px; }
            
            .camera-container {
                border-radius: 16px;
                margin-bottom: 12px;
            }
            
            .quality-panel {
                padding: 10px;
                border-radius: 12px;
                margin-bottom: 12px;
            }
            
            .quality-grid {
                gap: 4px;
            }
            
            .quality-item {
                padding: 6px 2px;
                font-size: 8px;
            }
            
            .quality-icon {
                font-size: 12px;
            }
            
            .signals-row {
                gap: 4px;
                margin-top: 8px;
                padding-top: 8px;
            }
            
            .signal-item {
                padding: 4px;
            }
            
            .signal-label { font-size: 7px; }
            .signal-value { font-size: 10px; }
            
            .btn {
                padding: 12px;
                font-size: 14px;
                border-radius: 10px;
            }
            
            .debug-panel {
                font-size: 8px;
                padding: 6px;
                max-width: 100px;
            }
            
            .status-text h2 { font-size: 14px; }
            .status-text p { font-size: 11px; }
}

        /* Small phones */
        @media (max-width: 360px) {
            .quality-grid {
                grid-template-columns: repeat(4, 1fr);
            }
            
            .quality-item {
                padding: 4px 1px;
            }
            
            .debug-panel {
                display: none;
            }
        }

        /* Landscape mode - hide some elements */
        @media (max-height: 500px) and (orientation: landscape) {
            .header { display: none; }
            .signals-row { display: none; }
            .debug-panel { display: none; }
            
            .camera-container {
                aspect-ratio: 4/3;
                max-height: 70vh;
            }
        }

        .header {
            text-align: center;
            margin-bottom: 16px;
        }
        .header h1 { font-size: 20px; font-weight: 600; margin-bottom: 4px; }
        .header p { font-size: 13px; color: var(--text-muted); }

        /* Camera */
        .camera-container {
            position: relative;
            width: 100%;
            aspect-ratio: 3/4;
            background: #000;
            border-radius: 20px;
            overflow: hidden;
            margin-bottom: 16px;
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
        }

        .overlay {
            position: absolute;
            inset: 0;
            pointer-events: none;
        }


        /* Regula-like oval UI */
        .oval-ui{
            position:absolute;
            inset:0;
            pointer-events:none;
            transition: filter 0.2s ease;
        }
        .oval-svg{ width:100%; height:100%; display:block; }
        .oval-dim{ fill: rgba(0,0,0,0.72); }
        .oval-ring{
            fill:none;
            stroke: rgba(255,255,255,0.28);
            stroke-width: 2.2;
        }
        .oval-glow{
            fill:none;
            stroke: rgba(255,255,255,0.10);
            stroke-width: 10;
            opacity: 0.0;
            transition: opacity 0.2s ease;
        }
        .oval-ui.detecting .oval-ring{ stroke: rgba(245,158,11,0.95); }
        .oval-ui.detecting .oval-glow{ opacity: 0.35; stroke: rgba(245,158,11,0.55); }
        .oval-ui.valid .oval-ring{ stroke: rgba(34,197,94,0.95); }
        .oval-ui.valid .oval-glow{ opacity: 0.35; stroke: rgba(34,197,94,0.55); }
        .oval-ui.invalid .oval-ring{ stroke: rgba(239,68,68,0.95); }
        .oval-ui.invalid .oval-glow{ opacity: 0.35; stroke: rgba(239,68,68,0.55); }

        
        /* Sweep ring */
        .oval-sweep{
            fill:none;
            stroke: rgba(255,255,255,0.0);
            stroke-width: 3.6;
            stroke-linecap: round;
            stroke-dasharray: 36 520; /* arc + gap (approx for ellipse) */
            stroke-dashoffset: 0;
            opacity: 0.0;
        }
        .oval-ui.capturing .oval-sweep{
            opacity: 0.95;
            stroke: rgba(255,255,255,0.85);
            animation: ovalSweep 1.1s linear infinite;
        }
        .oval-ui.detecting .oval-sweep{
            opacity: 0.55;
            stroke: rgba(255,255,255,0.45);
            animation: ovalSweep 1.4s linear infinite;
        }
        @keyframes ovalSweep{
            from { stroke-dashoffset: 0; }
            to { stroke-dashoffset: -556; }
        }

        /* Direction arrows */
        .oval-arrows{
            position:absolute;
            inset:0;
            display:block;
        }
        .oval-arrows .arrow{
            position:absolute;
            width: 34px;
            height: 34px;
            display:flex;
            align-items:center;
            justify-content:center;
            border-radius: 999px;
            background: rgba(0,0,0,0.35);
            color: rgba(255,255,255,0.92);
            font-size: 16px;
            opacity: 0.0;
            transform: scale(0.95);
            transition: opacity 0.12s ease, transform 0.12s ease;
            user-select:none;
            -webkit-user-select:none;
        }
        .oval-ui.show-up .oval-arrows .arrow-up,
        .oval-ui.show-down .oval-arrows .arrow-down,
        .oval-ui.show-left .oval-arrows .arrow-left,
        .oval-ui.show-right .oval-arrows .arrow-right{
            opacity: 0.95;
            transform: scale(1.0);
        }
        .oval-arrows .arrow-up{ left: 50%; top: 14%; transform: translateX(-50%) scale(0.95); }
        .oval-arrows .arrow-down{ left: 50%; bottom: 18%; transform: translateX(-50%) scale(0.95); }
        .oval-arrows .arrow-left{ left: 10%; top: 52%; transform: translateY(-50%) scale(0.95); }
        .oval-arrows .arrow-right{ right: 10%; top: 52%; transform: translateY(-50%) scale(0.95); }

        /* Make SVG stable across browsers */
        .oval-svg{
            width:100%;
            height:100%;
        }

        /* Progress */
        .progress-container {
            position: absolute;
            top: 12px;
            left: 12px;
            right: 12px;
        }
        .progress-bar {
            height: 4px;
            background: rgba(255,255,255,0.1);
            border-radius: 2px;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            width: 0%;
            background: var(--success);
            transition: width 0.3s;
        }

        /* Frame indicators */
        .frames-indicator {
            position: absolute;
            top: 24px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 8px;
        }
        .frame-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: rgba(255,255,255,0.2);
            transition: all 0.2s;
        }
        .frame-dot.captured { background: var(--success); }
        .frame-dot.current { background: var(--warning); animation: pulse 0.8s ease infinite; }
        @keyframes pulse { 0%,100% { transform: scale(1); } 50% { transform: scale(1.3); } }

        /* Status */
        .status-bar {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            padding: 16px;
            background: linear-gradient(transparent, rgba(0,0,0,0.85));
        }
        .status-row {
            display: flex;
            align-items: center;
            gap: 12px;
        }
        .status-icon {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: rgba(255,255,255,0.1);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 18px;
        }
        .status-text h2 { font-size: 15px; font-weight: 600; margin-bottom: 2px; }
        .status-text p { font-size: 12px; color: var(--text-muted); }

        /* Debug info */
        .debug-panel {
            position: absolute;
            top: 12px;
            right: 12px;
            background: rgba(0,0,0,0.7);
            padding: 8px;
            border-radius: 8px;
            font-size: 9px;
            font-family: monospace;
            color: var(--text-muted);
            max-width: 120px;
        }
        .debug-row {
            display: flex;
            justify-content: space-between;
            margin-bottom: 2px;
        }
        .debug-value { color: var(--text); }
        .debug-value.pass { color: var(--success); }
        .debug-value.fail { color: var(--error); }

        /* Loading overlay */
        .loading-overlay {
            position: absolute;
            inset: 0;
            background: rgba(0,0,0,0.85);
            display: none;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            gap: 16px;
            border-radius: 20px;
        }
        .loading-overlay.active { display: flex; }
        .spinner {
            width: 44px;
            height: 44px;
            border: 3px solid rgba(255,255,255,0.1);
            border-top-color: var(--primary);
            border-radius: 50%;
            animation: spin 0.8s linear infinite;
        }
        @keyframes spin { to { transform: rotate(360deg); } }
        .loading-text { font-size: 14px; color: var(--text-muted); text-align: center; }

        /* Quality panel */
        .quality-panel {
            background: var(--surface);
            border-radius: 14px;
            padding: 14px;
            margin-bottom: 16px;
        }
        .quality-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }
        .quality-title {
            font-size: 11px;
            font-weight: 600;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        .quality-mode {
            font-size: 9px;
            padding: 3px 8px;
            background: rgba(34,197,94,0.15);
            color: var(--success);
            border-radius: 8px;
        }
        .quality-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 6px;
        }
        .quality-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 4px;
            padding: 8px 4px;
            background: rgba(255,255,255,0.03);
            border-radius: 8px;
            font-size: 9px;
            color: var(--text-muted);
            text-align: center;
        }
        .quality-icon {
            font-size: 14px;
            transition: all 0.15s;
        }
        .quality-item.pass .quality-icon { color: var(--success); }
        .quality-item.fail .quality-icon { color: var(--error); }

        /* Soft signals */
        .signals-row {
            display: flex;
            gap: 8px;
            margin-top: 10px;
            padding-top: 10px;
            border-top: 1px solid var(--border);
        }
        .signal-item {
            flex: 1;
            padding: 6px;
            background: rgba(255,255,255,0.02);
            border-radius: 6px;
            text-align: center;
        }
        .signal-label { font-size: 8px; color: var(--text-muted); margin-bottom: 2px; }
        .signal-value { font-size: 11px; font-weight: 600; }

        /* Button */
        .btn {
            width: 100%;
            padding: 14px;
            border: none;
            border-radius: 12px;
            font-size: 15px;
            font-weight: 600;
            cursor: pointer;
            font-family: inherit;
            transition: all 0.2s;
        }
        .btn-primary { background: var(--primary); color: white; }
        .btn-primary:disabled { opacity: 0.5; cursor: not-allowed; }

        /* Result screen */
        .result-screen {
            display: none;
            flex-direction: column;
            align-items: center;
            text-align: center;
            padding: 40px 20px;
        }
        .result-screen.active { display: flex; }
        .result-icon {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 40px;
            margin-bottom: 20px;
        }
        .result-icon.success { background: rgba(34,197,94,0.12); }
        .result-icon.error { background: rgba(239,68,68,0.12); }
        .result-title { font-size: 22px; font-weight: 600; margin-bottom: 6px; }
        .result-subtitle { font-size: 14px; color: var(--text-muted); margin-bottom: 24px; }
        .result-photo {
            width: 100px;
            height: 130px;
            object-fit: cover;
            border-radius: 12px;
            border: 3px solid var(--success);
            margin-bottom: 24px;
        }

        .hidden { display: none !important; }
        #canvas, #cropCanvas { display: none; }
    </style>
</head>
<body>
    <div class="app">
        <!-- Main Flow -->
        <div id="mainFlow">
            <div class="header">
                <h1>Identity Verification</h1>
                <p>Position your face and hold naturally</p>
            </div>

            <div class="camera-container">
                <video id="video" autoplay playsinline muted></video>
                
                <div class="overlay">
                    <div class="oval-ui" id="faceOval" aria-hidden="true">
                        <svg class="oval-svg" viewBox="0 0 300 400" preserveAspectRatio="xMidYMid meet">
                            <defs>
                                <mask id="ovalHole">
                                    <rect x="0" y="0" width="300" height="400" fill="white"></rect>
                                    <ellipse cx="150" cy="205" rx="86" ry="122" fill="black"></ellipse>
                                </mask>
                                <filter id="ovalGlow" x="-50%" y="-50%" width="200%" height="200%">
                                    <feGaussianBlur stdDeviation="3.5" result="blur"></feGaussianBlur>
                                    <feMerge>
                                        <feMergeNode in="blur"></feMergeNode>
                                        <feMergeNode in="SourceGraphic"></feMergeNode>
                                    </feMerge>
                                </filter>
                            </defs>

                            <rect class="oval-dim" x="0" y="0" width="300" height="400" mask="url(#ovalHole)"></rect>
                            <ellipse class="oval-ring" cx="150" cy="205" rx="86" ry="122" vector-effect="non-scaling-stroke"></ellipse>
                            <ellipse class="oval-sweep" cx="150" cy="205" rx="86" ry="122" vector-effect="non-scaling-stroke"></ellipse>
                            <ellipse class="oval-glow" cx="150" cy="205" rx="86" ry="122" vector-effect="non-scaling-stroke" filter="url(#ovalGlow)"></ellipse>
                        </svg>
                    </div>

                </div>

                <div class="loading-overlay" id="loadingOverlay">
                    <div class="spinner"></div>
                    <div class="loading-text" id="loadingText">Initializing...</div>
                </div>
            </div>

            <button class="btn btn-primary" id="startBtn" disabled>Loading MediaPipe...</button>
        </div>

        <!-- Result Screen -->
        <div class="result-screen" id="resultScreen">
            <div class="result-icon success" id="resultIcon">✓</div>
            <h1 class="result-title" id="resultTitle">Verified!</h1>
            <p class="result-subtitle" id="resultSubtitle">Identity confirmed</p>
            <img class="result-photo" id="resultPhoto" src="" alt="">
            <button class="btn btn-primary" id="doneBtn">Done</button>
        </div>
    </div>

    <canvas id="canvas"></canvas>
    <canvas id="cropCanvas" width="224" height="224"></canvas>

    <script type="module">
    /**
     * PASSIVE FACE LIVENESS - CLIENT
     * ===============================
     * 
     * MediaPipe Face Detector + Landmarker (WASM)
     * Hard gates + Soft signals + Randomized capture
     * 
     * Outputs 5 frames with metadata to server for PAD scoring
     */

    import { FaceDetector, FaceLandmarker, FilesetResolver } from 
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/+esm';

    // ======================== CONFIGURATION ========================
    const CONFIG = {
        API_URL: 'http://localhost:5000',
        
        // Hard Gates (adjusted per your spec)
        FACE_CONFIDENCE: 0.85,
        FACE_RATIO_MIN: 0.08,    // Minimum face size
        FACE_RATIO_MAX: 0.55,    // Maximum face size
        MAX_YAW: 25,
        MAX_PITCH: 25,      // Relaxed - natural phone/laptop viewing angle
        MAX_ROLL: 18,
        LUMA_MIN: 50,
        LUMA_MAX: 200,
        LUMA_RANGE_MIN: 35,
        SHARPNESS_MIN: 60,      // Laplacian variance
        
        // Capture settings
        TOTAL_FRAMES: 5,
        CAPTURE_WINDOW_MS: 3000,
        MIN_FRAME_SPACING_MS: 250,
        MIN_POSE_CHANGE_YAW: 3,
        MIN_POSE_CHANGE_PITCH: 2,
        FRAMES_WITH_POSE_CHANGE: 2,
        
        // Timing
        DETECTION_INTERVAL_MS: 80,  // ~12 FPS
        
        // Anti-tamper
        SESSION_TTL_MS: 30000,
        
        // Image output
        CROP_SIZE: 224,
        JPEG_QUALITY: 0.75,
    };

    // ======================== STATE ========================
    const state = {
        // MediaPipe
        faceDetector: null,
        faceLandmarker: null,
        
        // Camera
        stream: null,
        video: null,
        
        // Detection loop
        isRunning: false,
        loopId: null,
        lastFrameTime: 0,
        fps: 0,
        
        // Session
        sessionId: null,
        nonce: null,
        sessionStart: 0,
        
        // Quality tracking
        currentQuality: {},
        poseHistory: [],
        landmarkHistory: [],
        
        // Capture
        capturedFrames: [],
        captureSchedule: [],
        lastCaptureTime: 0,
        validFrameCount: 0,
        
        // Soft signals
        jitterScore: 0,
        entropyScore: 0,
        uniformityScore: 0,
    };

    // ======================== DOM ========================
    const $ = id => document.getElementById(id);
    const video = $('video');
    const canvas = $('canvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    const cropCanvas = $('cropCanvas');
    const cropCtx = cropCanvas.getContext('2d');

    // ======================== INITIALIZATION ========================
    
    async function initialize() {
        showLoading('Loading MediaPipe...');

        // If you opened this page via file://, some browsers (esp. Safari) can stall ES module/WASM loads.
        // Recommended: serve over HTTP, e.g. `python3 -m http.server 8000` then open `http://localhost:8000/`.
        if (location.protocol === 'file:') {
            $('loadingText').textContent = 'Tip: open via http:// (not file://) for reliable MediaPipe loading.';
        }

        const withTimeout = (p, ms, label) => Promise.race([
            p,
            new Promise((_, reject) => setTimeout(() => reject(new Error(label || `Timeout after ${ms}ms`)), ms))
        ]);

        try {
            $('loadingText').textContent = 'Downloading MediaPipe assets...';

            const vision = await withTimeout(
                FilesetResolver.forVisionTasks('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm'),
                25000,
                'MediaPipe WASM load timeout'
            );

            const createAll = async (delegate) => {
                // Face Detector
                state.faceDetector = await FaceDetector.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite',
                        delegate
                    },
                    runningMode: 'VIDEO',
                    minDetectionConfidence: 0.5
                });

                // Face Landmarker
                state.faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                        delegate
                    },
                    runningMode: 'VIDEO',
                    numFaces: 1,
                    minFaceDetectionConfidence: 0.5,
                    minTrackingConfidence: 0.5,
                    outputFaceBlendshapes: false
                });
            };

            // Try GPU first, fallback to CPU (Safari often fails GPU delegate)
            try {
                $('loadingText').textContent = 'Initializing (GPU)...';
                await withTimeout(createAll('GPU'), 15000, 'GPU init timeout');
                $('modeLabel').textContent = 'MediaPipe GPU';
            } catch (gpuErr) {
                console.warn('GPU delegate failed, falling back to CPU:', gpuErr);
                $('loadingText').textContent = 'Initializing (CPU)...';
                await withTimeout(createAll('CPU'), 20000, 'CPU init timeout');
                $('modeLabel').textContent = 'MediaPipe CPU';
            }

            console.log('✓ MediaPipe loaded');
            hideLoading();
            setStartButton('Start Verification', true);

        } catch (error) {
            console.error('MediaPipe failed:', error);
            $('loadingText').textContent = 'Failed to load MediaPipe. Check internet, or open via http:// (not file://), then refresh.';
            // Keep button disabled to avoid broken flow; user can refresh.
            setStartButton('Loading failed', false);
        }
    }

    // ======================== SESSION MANAGEMENT ========================
    
    async function startSession() {
        try {
            const response = await fetch(`${CONFIG.API_URL}/session/start`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' }
            });
            
            if (!response.ok) throw new Error('Session failed');
            
            const data = await response.json();
            state.sessionId = data.session_id;
            state.nonce = data.nonce;
            state.sessionStart = Date.now();
            
            console.log('✓ Session started:', state.sessionId);
            return true;
            
        } catch (error) {
            console.error('Session error:', error);
            // Continue without session for demo
            state.sessionId = 'demo-' + Date.now();
            state.nonce = Math.random().toString(36).substring(2);
            state.sessionStart = Date.now();
            return true;
        }
    }
    
    function generateCaptureSchedule() {
        // Randomized capture times within the window
        const schedule = [];
        const windowMs = CONFIG.CAPTURE_WINDOW_MS;
        const numFrames = CONFIG.TOTAL_FRAMES;
        const minSpacing = CONFIG.MIN_FRAME_SPACING_MS;
        
        // Divide window into segments with randomization
        const segmentSize = windowMs / numFrames;
        
        for (let i = 0; i < numFrames; i++) {
            const baseTime = i * segmentSize;
            const jitter = Math.random() * (segmentSize - minSpacing);
            schedule.push(Math.round(baseTime + jitter));
        }
        
        // Ensure minimum spacing
        for (let i = 1; i < schedule.length; i++) {
            if (schedule[i] - schedule[i-1] < minSpacing) {
                schedule[i] = schedule[i-1] + minSpacing;
            }
        }
        
        console.log('Capture schedule:', schedule);
        return schedule;
    }

    // ======================== HARD GATES ========================
    
    
    // ======================== REALISM HELPERS ========================
    // Smooth noisy signals so UI doesn't flicker (vendor trick)
    const SMOOTH = {
        bbox: 0.35,   // lower = smoother
        pose: 0.30,
        fit:  0.25,
        msgHoldMs: 220
    };

    const smoothState = {
        cx: null, cy: null, bw: null, bh: null,
        yaw: 0, pitch: 0, roll: 0,
        fit: 0,
        lastMsg: "",
        lastMsgCandidate: "",
        lastMsgSince: 0
    };

    function ema(prev, next, alpha){
        if (prev === null || prev === undefined) return next;
        return prev + alpha * (next - prev);
    }

    // Oval in normalized [0..1] coords (matches SVG proportions)
    const OVAL = {
        cx: 0.5, cy: 0.5125, // center (approx 205/400)
        rx: 0.2867, ry: 0.305, // 86/300, 122/400
        margin: 0.04          // safety margin
    };

    function computeOvalFit(bbox, w, h){
        const cx = (bbox.originX + bbox.width * 0.5) / w;
        const cy = (bbox.originY + bbox.height * 0.5) / h;
        const nx = (cx - OVAL.cx) / (OVAL.rx - OVAL.margin);
        const ny = (cy - OVAL.cy) / (OVAL.ry - OVAL.margin);
        const inside = (nx*nx + ny*ny) <= 1.0;

        // Direction cues (based on center)
        const dx = cx - OVAL.cx;
        const dy = cy - OVAL.cy;

        // Fit score: 1 = centered, 0 = far outside
        const dist = Math.sqrt(nx*nx + ny*ny);
        const fitScore = Math.max(0, Math.min(1, 1 - (dist - 0.35))); // forgiving near center

        return { cx, cy, inside, dx, dy, fitScore };
    }

    function stableMessage(candidate){
        const now = performance.now();
        if (candidate !== smoothState.lastMsgCandidate){
            smoothState.lastMsgCandidate = candidate;
            smoothState.lastMsgSince = now;
            return smoothState.lastMsg; // keep old until held
        }
        if ((now - smoothState.lastMsgSince) >= SMOOTH.msgHoldMs){
            smoothState.lastMsg = candidate;
        }
        return smoothState.lastMsg;
    }

function checkHardGates(detection, landmarks, blendshapes, imageData) {
        const gates = {
            face: false,
            size: false,
            pose: false,            light: false,
            sharp: false,
            landmarks: false,
            motion: false,
            fit: false
        };
        
        let message = 'Center your face in the oval';
        const w = canvas.width;
        const h = canvas.height;
        
        // 1. Face detected with confidence
        if (!detection || detection.categories[0].score < CONFIG.FACE_CONFIDENCE) {
            message = 'No face detected';
            return { gates, allPass: false, message, pose: null };
        }
        gates.face = true;
        
        const bbox = detection.boundingBox;
        
        // Smooth bbox center/size
        const rawCx = bbox.originX + bbox.width * 0.5;
        const rawCy = bbox.originY + bbox.height * 0.5;
        smoothState.cx = ema(smoothState.cx, rawCx, SMOOTH.bbox);
        smoothState.cy = ema(smoothState.cy, rawCy, SMOOTH.bbox);
        smoothState.bw = ema(smoothState.bw, bbox.width, SMOOTH.bbox);
        smoothState.bh = ema(smoothState.bh, bbox.height, SMOOTH.bbox);

        const smoothedBox = {
            originX: smoothState.cx - smoothState.bw * 0.5,
            originY: smoothState.cy - smoothState.bh * 0.5,
            width: smoothState.bw,
            height: smoothState.bh
        };

        // Regula/Incode feel: fixed oval target; guide user to align
        const fit = computeOvalFit(smoothedBox, w, h);
        smoothState.fit = ema(smoothState.fit, fit.fitScore, SMOOTH.fit);
        
        // 2. Face size ratio
        const faceArea = smoothedBox.width * smoothedBox.height;
        const frameArea = w * h;
        const ratio = faceArea / frameArea;
        
        // 2b. Oval fit (direction guidance)
        // If face is off-center, show arrows and block capture even if size/pose are ok.
        if (!fit.inside) {
            // Determine direction arrows (deadzone to prevent flicker)
            const dead = 0.035;
            const showLeft = fit.dx > dead;
            const showRight = fit.dx < -dead;
            const showUp = fit.dy > dead;
            const showDown = fit.dy < -dead;

            // We encode arrow classes via message later (updateStatus)
            state._arrowClass = `${showUp ? ' show-up' : ''}${showDown ? ' show-down' : ''}${showLeft ? ' show-left' : ''}${showRight ? ' show-right' : ''}`;

            message = 'Center your face';
        } else {
            gates.fit = true;
            state._arrowClass = '';
        }

        if (ratio < CONFIG.FACE_RATIO_MIN) {
            if (gates.fit)
            message = 'Move closer';
        } else if (ratio > CONFIG.FACE_RATIO_MAX) {
            if (gates.fit)
            message = 'Move back';
        } else {
            gates.size = true;
        }
        
        // 3. Pose estimation (from landmarks)
        const poseRaw = estimatePose(landmarks);
        smoothState.yaw = ema(smoothState.yaw, poseRaw.yaw, SMOOTH.pose);
        smoothState.pitch = ema(smoothState.pitch, poseRaw.pitch, SMOOTH.pose);
        smoothState.roll = ema(smoothState.roll, poseRaw.roll, SMOOTH.pose);
        const pose = { yaw: smoothState.yaw, pitch: smoothState.pitch, roll: smoothState.roll };
        
        // Pose must be frontal for reliable eye detection
        if (gates.fit && Math.abs(pose.yaw) > CONFIG.MAX_YAW) {
            message = pose.yaw > 0 ? 'Turn head left' : 'Turn head right';
        } else if (gates.fit && Math.abs(pose.pitch) > CONFIG.MAX_PITCH) {
            message = pose.pitch > 0 ? 'Look up at camera' : 'Raise your head';
        } else if (gates.fit && Math.abs(pose.roll) > CONFIG.MAX_ROLL) {
            message = 'Straighten head';
        } else {
            gates.pose = true;
        }
        // 4. Lighting check
        const lighting = analyzeLighting(imageData);
        if (lighting.mean < CONFIG.LUMA_MIN) {
            if (gates.fit) message = 'Too dark - more light needed';
        } else if (lighting.mean > CONFIG.LUMA_MAX) {
            if (gates.fit) message = 'Too bright';
        } else if (lighting.range < CONFIG.LUMA_RANGE_MIN) {
            if (gates.fit) message = 'Low contrast';
        } else {
            gates.light = true;
        }

// 6. Sharpness
        const sharpness = calculateSharpness(imageData);
        if (sharpness < CONFIG.SHARPNESS_MIN) {
            if (gates.fit) message = 'Image blurry - hold still';
        } else {
            gates.sharp = true;
        }

// 7. Key landmarks visible
        const landmarksVisible = checkLandmarksVisible(landmarks);
        if (!landmarksVisible) {
            if (gates.fit) message = 'Face partially hidden';
        } else {
            gates.landmarks = true;
        }

// 8. Motion check (natural movement)
        const hasMotion = checkNaturalMotion(pose);
        gates.motion = hasMotion || state.capturedFrames.length === 0;
        
        const allPass = Object.values(gates).every(v => v);
        if (allPass) message = 'Perfect - capturing...';
        
        return { gates, allPass, message, pose, lighting, sharpness };
    }

    // ======================== POSE ESTIMATION ========================
    
    function estimatePose(landmarks) {
        if (!landmarks || landmarks.length < 468) {
            return { yaw: 0, pitch: 0, roll: 0 };
        }
        
        // Key landmark indices
        const noseTip = landmarks[4];
        const leftEyeOuter = landmarks[33];
        const rightEyeOuter = landmarks[263];
        const leftMouth = landmarks[61];
        const rightMouth = landmarks[291];
        const chin = landmarks[152];
        const forehead = landmarks[10];
        
        // Eye distance for normalization
        const eyeDist = Math.sqrt(
            Math.pow(rightEyeOuter.x - leftEyeOuter.x, 2) +
            Math.pow(rightEyeOuter.y - leftEyeOuter.y, 2)
        );
        
        // Yaw: nose offset from eye midpoint
        const eyeMidX = (leftEyeOuter.x + rightEyeOuter.x) / 2;
        const noseOffsetX = (noseTip.x - eyeMidX) / eyeDist;
        const yaw = Math.atan(noseOffsetX * 2) * (180 / Math.PI) * 1.5;
        
        // Pitch: vertical nose position relative to eyes
        const eyeMidY = (leftEyeOuter.y + rightEyeOuter.y) / 2;
        const noseOffsetY = (noseTip.y - eyeMidY) / eyeDist;
        const pitch = Math.atan(noseOffsetY) * (180 / Math.PI) * 0.8;  // Reduced multiplier
        
        // Roll: eye line angle
        const roll = Math.atan2(
            rightEyeOuter.y - leftEyeOuter.y,
            rightEyeOuter.x - leftEyeOuter.x
        ) * (180 / Math.PI);
        
        return { yaw, pitch, roll };
    }

    // ======================== IMAGE ANALYSIS ========================
    
    function analyzeLighting(imageData) {
        const data = imageData.data;
        let sum = 0;
        let min = 255;
        let max = 0;
        const samples = Math.floor(data.length / 16); // Sample every 4th pixel
        
        for (let i = 0; i < data.length; i += 16) {
            const luma = 0.299 * data[i] + 0.587 * data[i+1] + 0.114 * data[i+2];
            sum += luma;
            if (luma < min) min = luma;
            if (luma > max) max = luma;
        }
        
        return {
            mean: sum / samples,
            range: max - min,
            min,
            max
        };
    }
    
    function calculateSharpness(imageData) {
        // Laplacian variance
        const w = canvas.width;
        const h = canvas.height;
        const data = imageData.data;
        
        let sum = 0;
        let sumSq = 0;
        let count = 0;
        
        // Sample center region
        const startX = Math.floor(w * 0.25);
        const endX = Math.floor(w * 0.75);
        const startY = Math.floor(h * 0.25);
        const endY = Math.floor(h * 0.75);
        
        for (let y = startY + 1; y < endY - 1; y += 2) {
            for (let x = startX + 1; x < endX - 1; x += 2) {
                const idx = (y * w + x) * 4;
                const idxUp = ((y-1) * w + x) * 4;
                const idxDown = ((y+1) * w + x) * 4;
                const idxLeft = (y * w + (x-1)) * 4;
                const idxRight = (y * w + (x+1)) * 4;
                
                // Grayscale Laplacian
                const center = (data[idx] + data[idx+1] + data[idx+2]) / 3;
                const up = (data[idxUp] + data[idxUp+1] + data[idxUp+2]) / 3;
                const down = (data[idxDown] + data[idxDown+1] + data[idxDown+2]) / 3;
                const left = (data[idxLeft] + data[idxLeft+1] + data[idxLeft+2]) / 3;
                const right = (data[idxRight] + data[idxRight+1] + data[idxRight+2]) / 3;
                
                const laplacian = Math.abs(4 * center - up - down - left - right);
                sum += laplacian;
                sumSq += laplacian * laplacian;
                count++;
            }
        }
        
        const mean = sum / count;
        const variance = (sumSq / count) - (mean * mean);
        
        return variance;
    }
    
    function checkLandmarksVisible(landmarks) {
        if (!landmarks || landmarks.length < 468) return false;
        
        // Check key landmarks have reasonable confidence
        const keyIndices = [
            4,    // nose tip
            33,   // left eye outer
            263,  // right eye outer
            61,   // left mouth
            291,  // right mouth
            152,  // chin
            10    // forehead
        ];
        
        for (const idx of keyIndices) {
            const lm = landmarks[idx];
            if (!lm || lm.x < 0.05 || lm.x > 0.95 || lm.y < 0.05 || lm.y > 0.95) {
                return false;
            }
        }
        
        return true;
    }

    // ======================== MOTION ANALYSIS ========================
    
    function checkNaturalMotion(currentPose) {
        if (state.poseHistory.length < 3) {
            state.poseHistory.push(currentPose);
            return true;
        }
        
        state.poseHistory.push(currentPose);
        if (state.poseHistory.length > 30) {
            state.poseHistory.shift();
        }
        
        // Check for sufficient pose variation
        let poseChangeCount = 0;
        
        for (let i = 1; i < state.poseHistory.length; i++) {
            const prev = state.poseHistory[i-1];
            const curr = state.poseHistory[i];
            
            const yawChange = Math.abs(curr.yaw - prev.yaw);
            const pitchChange = Math.abs(curr.pitch - prev.pitch);
            
            if (yawChange >= CONFIG.MIN_POSE_CHANGE_YAW || 
                pitchChange >= CONFIG.MIN_POSE_CHANGE_PITCH) {
                poseChangeCount++;
            }
        }
        
        return poseChangeCount >= CONFIG.FRAMES_WITH_POSE_CHANGE;
    }
    
    function calculateJitter(landmarks) {
        if (!landmarks || state.landmarkHistory.length < 5) {
            if (landmarks) {
                state.landmarkHistory.push(landmarks.slice(0, 10)); // Store first 10 landmarks
            }
            return 0.5;
        }
        
        state.landmarkHistory.push(landmarks.slice(0, 10));
        if (state.landmarkHistory.length > 15) {
            state.landmarkHistory.shift();
        }
        
        // Calculate average movement
        let totalMovement = 0;
        for (let i = 1; i < state.landmarkHistory.length; i++) {
            for (let j = 0; j < 10; j++) {
                const prev = state.landmarkHistory[i-1][j];
                const curr = state.landmarkHistory[i][j];
                totalMovement += Math.sqrt(
                    Math.pow(curr.x - prev.x, 2) + Math.pow(curr.y - prev.y, 2)
                );
            }
        }
        
        const avgMovement = totalMovement / (state.landmarkHistory.length * 10);
        
        // Too static is suspicious (video replay), too jittery is bad quality
        if (avgMovement < 0.001) return 0.2;  // Suspiciously static
        if (avgMovement > 0.05) return 0.3;   // Too jittery
        return 0.8;  // Good natural movement
    }
    
    function calculateTextureEntropy(imageData) {
        // Simple entropy estimation
        const histogram = new Array(256).fill(0);
        const data = imageData.data;
        
        for (let i = 0; i < data.length; i += 4) {
            const gray = Math.round(0.299 * data[i] + 0.587 * data[i+1] + 0.114 * data[i+2]);
            histogram[gray]++;
        }
        
        const totalPixels = data.length / 4;
        let entropy = 0;
        
        for (let i = 0; i < 256; i++) {
            if (histogram[i] > 0) {
                const p = histogram[i] / totalPixels;
                entropy -= p * Math.log2(p);
            }
        }
        
        return Math.min(1, entropy / 8); // Normalize to 0-1
    }

    // ======================== FRAME CAPTURE ========================
    
    function shouldCaptureNow() {
        if (state.capturedFrames.length >= CONFIG.TOTAL_FRAMES) return false;
        
        const elapsed = Date.now() - state.sessionStart;
        const nextCaptureTime = state.captureSchedule[state.capturedFrames.length];
        
        if (elapsed >= nextCaptureTime) {
            const timeSinceLast = Date.now() - state.lastCaptureTime;
            return timeSinceLast >= CONFIG.MIN_FRAME_SPACING_MS;
        }
        
        return false;
    }
    
    function captureFrame(bbox, quality) {
        // Crop face region
        const padding = 0.3;
        const x = Math.max(0, bbox.originX - bbox.width * padding);
        const y = Math.max(0, bbox.originY - bbox.height * padding);
        const w = Math.min(canvas.width - x, bbox.width * (1 + padding * 2));
        const h = Math.min(canvas.height - y, bbox.height * (1 + padding * 2));
        
        // Draw cropped and resized to 224x224
        cropCtx.drawImage(
            canvas, 
            x, y, w, h,
            0, 0, CONFIG.CROP_SIZE, CONFIG.CROP_SIZE
        );
        
        const imageData = cropCanvas.toDataURL('image/jpeg', CONFIG.JPEG_QUALITY);
        
        // Generate hash for anti-tamper
        const frameId = state.capturedFrames.length;
        const hashInput = `${imageData.slice(-100)}|${state.nonce}|${frameId}`;
        const hash = simpleHash(hashInput);
        
        const frame = {
            image: imageData,
            frame_id: frameId,
            timestamp: Date.now() - state.sessionStart,
            hash: hash,
            metadata: {
                pose: quality.pose,
lighting: quality.lighting,
                sharpness: quality.sharpness,
                jitter: state.jitterScore,
                entropy: state.entropyScore
            }
        };
        
        state.capturedFrames.push(frame);
        state.lastCaptureTime = Date.now();
        
        console.log(`✓ Captured frame ${frameId + 1}/${CONFIG.TOTAL_FRAMES}`);
        
        return frame;
    }
    
    function simpleHash(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
            const char = str.charCodeAt(i);
            hash = ((hash << 5) - hash) + char;
            hash = hash & hash;
        }
        return hash.toString(16);
    }

    // ======================== UI (MINIMAL) ========================
    // User request: remove all visible quality gates, debug and signals.
    // Keep only: oval overlay + Start button + loading overlay + result screen.

    function setOvalState(stateName) {
        // stateName: 'idle' | 'detecting' | 'capturing' | 'success' | 'error'
        const el = $('faceOval');
        if (!el) return;
        el.className = `oval-ui ${stateName || ''}`;
    }

    function setStartButton(text, enabled) {
        const btn = $('startBtn');
        if (!btn) return;
        if (typeof text === 'string') btn.textContent = text;
        if (typeof enabled === 'boolean') btn.disabled = !enabled;
    }

    function showLoading(text) {
        const ov = $('loadingOverlay');
        if (ov) ov.classList.add('active');
        const lt = $('loadingText');
        if (lt && text) lt.textContent = text;
        setOvalState('capturing'); // keep sweep alive while verifying
    }

    function hideLoading() {
        const ov = $('loadingOverlay');
        if (ov) ov.classList.remove('active');
    }

    // ======================== MAIN DETECTION LOOP ========================
    
    async function detectionLoop() {
        if (!state.isRunning) return;
        
        const now = performance.now();
        state.fps = 1000 / (now - state.lastFrameTime);
        state.lastFrameTime = now;
        
        // Draw frame to canvas
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
        
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        
        // Run detection
        const timestamp = performance.now();
        const detections = state.faceDetector.detectForVideo(canvas, timestamp);
        const landmarksResult = state.faceLandmarker.detectForVideo(canvas, timestamp);
        
        const detection = detections.detections[0];
        const landmarks = landmarksResult.faceLandmarks[0];
        const blendshapes = landmarksResult.faceBlendshapes;
        
        // Check hard gates
        const quality = checkHardGates(detection, landmarks, blendshapes, imageData);
        
        // Update soft signals
        state.jitterScore = calculateJitter(landmarks);
        state.entropyScore = calculateTextureEntropy(imageData);
        state.uniformityScore = quality.lighting ? 
            Math.min(1, quality.lighting.range / 100) : 0.5;
        
        // Update UI
        if (quality.allPass) {
            state.validFrameCount++;
            
            // Check if should capture
            if (shouldCaptureNow()) {
                captureFrame(detection.boundingBox, quality);
                if (state.capturedFrames.length >= CONFIG.TOTAL_FRAMES) {
                    await submitToServer();
                    return;
                }
            }
            
            updateStatus('✓', 'Hold still',
                `Capturing ${state.capturedFrames.length + 1}/${CONFIG.TOTAL_FRAMES}...`, 'valid capturing');
        } else {
            const msg = stableMessage(quality.message);
            updateStatus('⚠️', msg,
                `${state.capturedFrames.length}/${CONFIG.TOTAL_FRAMES} captured`,
                quality.gates.face ? 'detecting' : 'invalid');
        }
        
        // Continue loop
        state.loopId = setTimeout(detectionLoop, CONFIG.DETECTION_INTERVAL_MS);
    }
    
    function stopLoop() {
        state.isRunning = false;
        if (state.loopId) {
            clearTimeout(state.loopId);
            state.loopId = null;
        }
    }

    // ======================== SERVER SUBMISSION ========================
    
    async function submitToServer() {
        stopLoop();
        showLoading('Verifying liveness...');
        
        try {
            const payload = {
                session_id: state.sessionId,
                nonce: state.nonce,
                frames: state.capturedFrames,
                client_metadata: {
                    user_agent: navigator.userAgent,
                    screen: `${screen.width}x${screen.height}`,
                    capture_duration_ms: Date.now() - state.sessionStart
                }
            };
            
            const response = await fetch(`${CONFIG.API_URL}/verify`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            
            if (!response.ok) throw new Error(`Server error: ${response.status}`);
            
            const result = await response.json();
            
            hideLoading();
            showResult(result);
            
        } catch (error) {
            console.error('Submission error:', error);
            hideLoading();
            
            // Show error result
            showResult({
                decision: 'ERROR',
                message: 'Connection error. Please try again.'
            });
        }
    }

    // ======================== RESULT ========================
    
    function showResult(result) {
        stopCamera();
        
        $('mainFlow').classList.add('hidden');
        $('resultScreen').classList.add('active');
        
        const isPass = result.decision === 'PASS';
        
        $('resultIcon').className = `result-icon ${isPass ? 'success' : 'error'}`;
        $('resultIcon').textContent = isPass ? '✓' : '✗';
        $('resultTitle').textContent = isPass ? 'Verified!' : 'Verification Failed';
        $('resultSubtitle').textContent = result.message || 
            (isPass ? 'Identity confirmed' : 'Please try again');
        
        if (isPass && state.capturedFrames.length > 0) {
            // Show best frame if server provided it, otherwise the last captured frame.
            let best = null;
            if (result && result.best_frame_id !== undefined && result.best_frame_id !== null) {
                best = state.capturedFrames.find(f => f.frame_id === result.best_frame_id) || null;
            }
            if (!best) best = state.capturedFrames[state.capturedFrames.length - 1];

            $('resultPhoto').src = best.image;
            $('resultPhoto').style.display = 'block';
        } else {
            $('resultPhoto').style.display = 'none';
        }
    }
    
    function restart() {
        $('resultScreen').classList.remove('active');
        $('mainFlow').classList.remove('hidden');
        
        // Reset state
        state.capturedFrames = [];
        state.poseHistory = [];
        state.landmarkHistory = [];
        state.validFrameCount = 0;
        
        // Reset UI (minimal)
        hideLoading();
        setOvalState('idle');
        setStartButton('Start Verification', true);
    }

    // ======================== CAMERA ========================
    
    async function startCamera() {
        try {
            // Detect if mobile
            const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
            
            // Mobile-optimized constraints
            const constraints = {
                video: {
                    facingMode: 'user',
                    width: { ideal: isMobile ? 480 : 640 },
                    height: { ideal: isMobile ? 640 : 480 },
                    frameRate: { ideal: 15, max: 30 }
                },
                audio: false
            };
            
            // Try to get camera with ideal constraints
            try {
                state.stream = await navigator.mediaDevices.getUserMedia(constraints);
            } catch (e) {
                // Fallback to basic constraints
                console.warn('Ideal constraints failed, trying fallback:', e);
                state.stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'user' },
                    audio: false
                });
            }
            
            video.srcObject = state.stream;
            
            // Wait for video to be ready
            await new Promise((resolve, reject) => {
                video.onloadedmetadata = () => {
                    video.play()
                        .then(resolve)
                        .catch(reject);
                };
                video.onerror = reject;
                setTimeout(() => reject(new Error('Video load timeout')), 10000);
            });
            
            console.log(`Camera started: ${video.videoWidth}x${video.videoHeight}`);
            return true;
            
        } catch (error) {
            console.error('Camera error:', error);
            
            // User-friendly error messages
            let message = 'Cannot access camera.';
            if (error.name === 'NotAllowedError') {
                message = 'Camera permission denied. Please allow camera access and try again.';
            } else if (error.name === 'NotFoundError') {
                message = 'No camera found. Please ensure your device has a front camera.';
            } else if (error.name === 'NotReadableError') {
                message = 'Camera is in use by another app. Please close other apps and try again.';
            }
            
            alert(message);
            return false;
        }
    }
    
    function stopCamera() {
        if (state.stream) {
            state.stream.getTracks().forEach(t => t.stop());
            state.stream = null;
        }
    }

    // ======================== EVENT HANDLERS ========================
    
    $('startBtn').addEventListener('click', async () => {
        $('startBtn').disabled = true;
        $('startBtn').textContent = 'Starting...';
        
        // Start session
        await startSession();
        
        // Generate capture schedule
        state.captureSchedule = generateCaptureSchedule();
        
        // Start camera
        if (!await startCamera()) {
            $('startBtn').disabled = false;
            $('startBtn').textContent = 'Start Verification';
            return;
        }
        
        // Reset state
        state.capturedFrames = [];
        state.poseHistory = [];
        state.landmarkHistory = [];
        state.validFrameCount = 0;
        state.lastFrameTime = performance.now();
        state.isRunning = true;
        
        $('startBtn').textContent = 'Scanning...';
        updateStatus('🔍', 'Scanning', 'Position your face in the oval', 'detecting');
        
        // Start detection loop
        setTimeout(detectionLoop, 100);
    });
    
    $('doneBtn').addEventListener('click', restart);
    
    window.addEventListener('beforeunload', () => {
        stopLoop();
        stopCamera();
    });

    // ======================== INIT ========================
    window.addEventListener('load', initialize);
    </script>
</body>
</html>
